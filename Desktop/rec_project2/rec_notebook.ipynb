{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.base import BaseEstimator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, SVD\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import string\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.base import BaseEstimator\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>is_paid</th>\n",
       "      <th>price</th>\n",
       "      <th>headline</th>\n",
       "      <th>num_subscribers</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>...</th>\n",
       "      <th>content_length_min</th>\n",
       "      <th>published_time</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>topic</th>\n",
       "      <th>language</th>\n",
       "      <th>course_url</th>\n",
       "      <th>instructor_name</th>\n",
       "      <th>instructor_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1766</td>\n",
       "      <td>84482.0</td>\n",
       "      <td>Ovation Public Speaking - Speaking Methods Mas...</td>\n",
       "      <td>True</td>\n",
       "      <td>59.99</td>\n",
       "      <td>Public speaking is a crucial skill to have in ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>234.0</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>Business</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Public Speaking</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/ovation-public-speaking-speaking-metho...</td>\n",
       "      <td>Ovation Public Speaking</td>\n",
       "      <td>/user/nickcunningham2/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1768</td>\n",
       "      <td>84660.0</td>\n",
       "      <td>Method Lesson 4: Speaking with Modulation</td>\n",
       "      <td>True</td>\n",
       "      <td>19.99</td>\n",
       "      <td>Speaking Method #4 focuses on Modulation.  Thi...</td>\n",
       "      <td>418.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>2022-04-02</td>\n",
       "      <td>Business</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Public Speaking</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/method-lesson-4-speaking-with-modulation/</td>\n",
       "      <td>Ovation Public Speaking</td>\n",
       "      <td>/user/nickcunningham2/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1778</td>\n",
       "      <td>84664.0</td>\n",
       "      <td>Method Lesson 5: Speaking with Enthusiasm</td>\n",
       "      <td>True</td>\n",
       "      <td>19.99</td>\n",
       "      <td>Lesson 5 focuses on Enthusiasm.  This course w...</td>\n",
       "      <td>522.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2022-04-15</td>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>Personal Development</td>\n",
       "      <td>Career Development</td>\n",
       "      <td>Public Speaking</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/method-lesson-5-speaking-with-enthusiasm/</td>\n",
       "      <td>Ovation Public Speaking</td>\n",
       "      <td>/user/nickcunningham2/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1780</td>\n",
       "      <td>84626.0</td>\n",
       "      <td>Method Lesson 3: Speaking with Power</td>\n",
       "      <td>True</td>\n",
       "      <td>24.99</td>\n",
       "      <td>Method Lesson 3 focuses on using power and int...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>Personal Development</td>\n",
       "      <td>Career Development</td>\n",
       "      <td>Public Speaking</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/method-lesson-3-speaking-with-power/</td>\n",
       "      <td>Ovation Public Speaking</td>\n",
       "      <td>/user/nickcunningham2/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1790</td>\n",
       "      <td>85752.0</td>\n",
       "      <td>Content Lesson 2: Subject Development</td>\n",
       "      <td>True</td>\n",
       "      <td>19.99</td>\n",
       "      <td>Content Lesson 2 focuses on Subject Developmen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2022-06-19</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>Business</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Presentation Skills</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/content-lesson-2-subject-development/</td>\n",
       "      <td>Ovation Public Speaking</td>\n",
       "      <td>/user/nickcunningham2/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36119</th>\n",
       "      <td>209729</td>\n",
       "      <td>4913954.0</td>\n",
       "      <td>Let's Speak Urdu - The Urdu Grammar</td>\n",
       "      <td>True</td>\n",
       "      <td>19.99</td>\n",
       "      <td>Urdu - Become fluent in this beautiful South A...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>Teaching &amp; Academics</td>\n",
       "      <td>Language Learning</td>\n",
       "      <td>Urdu Language</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/lets-speak-urdu-the-grammar/</td>\n",
       "      <td>Jawaid Hameed</td>\n",
       "      <td>/user/jawaid-hameed/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36120</th>\n",
       "      <td>209730</td>\n",
       "      <td>4914146.0</td>\n",
       "      <td>CompTIA Linux+ (XKO-004/005 # 2 Practice Exam ...</td>\n",
       "      <td>True</td>\n",
       "      <td>49.99</td>\n",
       "      <td>Practice Latest exam questions with detailed e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>IT &amp; Software</td>\n",
       "      <td>IT Certifications</td>\n",
       "      <td>CompTIA Linux+</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/comptia-linux-xko-004005-2-practice-ex...</td>\n",
       "      <td>Jean-François d'Halluin</td>\n",
       "      <td>/user/badre-lini/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36121</th>\n",
       "      <td>209731</td>\n",
       "      <td>4914002.0</td>\n",
       "      <td>CISSP 4 full exams #1 : All CISSP domains - 12...</td>\n",
       "      <td>True</td>\n",
       "      <td>49.99</td>\n",
       "      <td>Practice Latest exam questions with detailed e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>IT &amp; Software</td>\n",
       "      <td>IT Certifications</td>\n",
       "      <td>CISSP - Certified Information Systems Security...</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/cissp-4-full-exams-1-all-cissp-domains...</td>\n",
       "      <td>Jean-François d'Halluin</td>\n",
       "      <td>/user/badre-lini/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36122</th>\n",
       "      <td>209732</td>\n",
       "      <td>4913934.0</td>\n",
       "      <td>JD Edwards EnterpriseOne Fixed Assets Accounti...</td>\n",
       "      <td>True</td>\n",
       "      <td>119.99</td>\n",
       "      <td>Full-length course (Part-3 of 3) on JD Edwards...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>Finance &amp; Accounting</td>\n",
       "      <td>Other Finance &amp; Accounting</td>\n",
       "      <td>Financial Accounting</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/jde-fixed-assets-accounting-part-3/</td>\n",
       "      <td>Niranjan Bhatia</td>\n",
       "      <td>/user/systemic-software-solutions/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36123</th>\n",
       "      <td>209733</td>\n",
       "      <td>4914054.0</td>\n",
       "      <td>CISSP 4 full exams #2 : All CISSP domains - 12...</td>\n",
       "      <td>True</td>\n",
       "      <td>49.99</td>\n",
       "      <td>Practice Latest exam questions with detailed e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>IT &amp; Software</td>\n",
       "      <td>IT Certifications</td>\n",
       "      <td>CISSP - Certified Information Systems Security...</td>\n",
       "      <td>English</td>\n",
       "      <td>/course/cissp-4-full-exams-2-all-cissp-domains...</td>\n",
       "      <td>Jean-François d'Halluin</td>\n",
       "      <td>/user/badre-lini/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36124 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index         id                                              title  \\\n",
       "0        1766    84482.0  Ovation Public Speaking - Speaking Methods Mas...   \n",
       "1        1768    84660.0          Method Lesson 4: Speaking with Modulation   \n",
       "2        1778    84664.0          Method Lesson 5: Speaking with Enthusiasm   \n",
       "3        1780    84626.0               Method Lesson 3: Speaking with Power   \n",
       "4        1790    85752.0              Content Lesson 2: Subject Development   \n",
       "...       ...        ...                                                ...   \n",
       "36119  209729  4913954.0                Let's Speak Urdu - The Urdu Grammar   \n",
       "36120  209730  4914146.0  CompTIA Linux+ (XKO-004/005 # 2 Practice Exam ...   \n",
       "36121  209731  4914002.0  CISSP 4 full exams #1 : All CISSP domains - 12...   \n",
       "36122  209732  4913934.0  JD Edwards EnterpriseOne Fixed Assets Accounti...   \n",
       "36123  209733  4914054.0  CISSP 4 full exams #2 : All CISSP domains - 12...   \n",
       "\n",
       "       is_paid   price                                           headline  \\\n",
       "0         True   59.99  Public speaking is a crucial skill to have in ...   \n",
       "1         True   19.99  Speaking Method #4 focuses on Modulation.  Thi...   \n",
       "2         True   19.99  Lesson 5 focuses on Enthusiasm.  This course w...   \n",
       "3         True   24.99  Method Lesson 3 focuses on using power and int...   \n",
       "4         True   19.99  Content Lesson 2 focuses on Subject Developmen...   \n",
       "...        ...     ...                                                ...   \n",
       "36119     True   19.99  Urdu - Become fluent in this beautiful South A...   \n",
       "36120     True   49.99  Practice Latest exam questions with detailed e...   \n",
       "36121     True   49.99  Practice Latest exam questions with detailed e...   \n",
       "36122     True  119.99  Full-length course (Part-3 of 3) on JD Edwards...   \n",
       "36123     True   49.99  Practice Latest exam questions with detailed e...   \n",
       "\n",
       "       num_subscribers  avg_rating  num_reviews  num_comments  ...  \\\n",
       "0                  4.0         0.0          0.0           0.0  ...   \n",
       "1                418.0         3.0          1.0           1.0  ...   \n",
       "2                522.0         4.8          5.0           1.0  ...   \n",
       "3                  0.0         0.0          0.0           0.0  ...   \n",
       "4                  0.0         0.0          0.0           0.0  ...   \n",
       "...                ...         ...          ...           ...  ...   \n",
       "36119              3.0         0.0          0.0           0.0  ...   \n",
       "36120              0.0         0.0          0.0           0.0  ...   \n",
       "36121              0.0         0.0          0.0           0.0  ...   \n",
       "36122              0.0         0.0          0.0           0.0  ...   \n",
       "36123              0.0         0.0          0.0           0.0  ...   \n",
       "\n",
       "       content_length_min  published_time last_update_date  \\\n",
       "0                   234.0      2022-05-17       2022-05-16   \n",
       "1                    37.0      2022-04-03       2022-04-02   \n",
       "2                    33.0      2022-04-15       2022-04-14   \n",
       "3                    45.0      2022-05-16       2022-05-15   \n",
       "4                    48.0      2022-06-19       2022-06-18   \n",
       "...                   ...             ...              ...   \n",
       "36119                54.0      2022-10-05       2022-10-06   \n",
       "36120                 0.0      2022-10-05       2022-10-05   \n",
       "36121                 0.0      2022-10-05       2022-10-05   \n",
       "36122                82.0      2022-10-05       2022-10-05   \n",
       "36123                 0.0      2022-10-05       2022-10-05   \n",
       "\n",
       "                   category                 subcategory  \\\n",
       "0                  Business               Communication   \n",
       "1                  Business               Communication   \n",
       "2      Personal Development          Career Development   \n",
       "3      Personal Development          Career Development   \n",
       "4                  Business               Communication   \n",
       "...                     ...                         ...   \n",
       "36119  Teaching & Academics           Language Learning   \n",
       "36120         IT & Software           IT Certifications   \n",
       "36121         IT & Software           IT Certifications   \n",
       "36122  Finance & Accounting  Other Finance & Accounting   \n",
       "36123         IT & Software           IT Certifications   \n",
       "\n",
       "                                                   topic language  \\\n",
       "0                                        Public Speaking  English   \n",
       "1                                        Public Speaking  English   \n",
       "2                                        Public Speaking  English   \n",
       "3                                        Public Speaking  English   \n",
       "4                                    Presentation Skills  English   \n",
       "...                                                  ...      ...   \n",
       "36119                                      Urdu Language  English   \n",
       "36120                                     CompTIA Linux+  English   \n",
       "36121  CISSP - Certified Information Systems Security...  English   \n",
       "36122                               Financial Accounting  English   \n",
       "36123  CISSP - Certified Information Systems Security...  English   \n",
       "\n",
       "                                              course_url  \\\n",
       "0      /course/ovation-public-speaking-speaking-metho...   \n",
       "1      /course/method-lesson-4-speaking-with-modulation/   \n",
       "2      /course/method-lesson-5-speaking-with-enthusiasm/   \n",
       "3           /course/method-lesson-3-speaking-with-power/   \n",
       "4          /course/content-lesson-2-subject-development/   \n",
       "...                                                  ...   \n",
       "36119               /course/lets-speak-urdu-the-grammar/   \n",
       "36120  /course/comptia-linux-xko-004005-2-practice-ex...   \n",
       "36121  /course/cissp-4-full-exams-1-all-cissp-domains...   \n",
       "36122        /course/jde-fixed-assets-accounting-part-3/   \n",
       "36123  /course/cissp-4-full-exams-2-all-cissp-domains...   \n",
       "\n",
       "               instructor_name                      instructor_url  \n",
       "0      Ovation Public Speaking              /user/nickcunningham2/  \n",
       "1      Ovation Public Speaking              /user/nickcunningham2/  \n",
       "2      Ovation Public Speaking              /user/nickcunningham2/  \n",
       "3      Ovation Public Speaking              /user/nickcunningham2/  \n",
       "4      Ovation Public Speaking              /user/nickcunningham2/  \n",
       "...                        ...                                 ...  \n",
       "36119            Jawaid Hameed                /user/jawaid-hameed/  \n",
       "36120  Jean-François d'Halluin                   /user/badre-lini/  \n",
       "36121  Jean-François d'Halluin                   /user/badre-lini/  \n",
       "36122          Niranjan Bhatia  /user/systemic-software-solutions/  \n",
       "36123  Jean-François d'Halluin                   /user/badre-lini/  \n",
       "\n",
       "[36124 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv('info2017.csv')\n",
    "df_comment = pd.read_csv('comment2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных курсов: 35\n",
      "Уникальных пользователей: 160\n"
     ]
    }
   ],
   "source": [
    "english_courses = df_info.copy()\n",
    "\n",
    "df_comment['date'] = pd.to_datetime(df_comment['date'], errors='coerce')\n",
    "df_comment_2022 = df_comment[df_comment['date'].dt.year == 2022]\n",
    "\n",
    "comment_counts = df_comment_2022['display_name'].value_counts()\n",
    "valid_users = comment_counts[(comment_counts >= 5) & (comment_counts <= 100)].index\n",
    "df_comment_filtered = df_comment_2022[df_comment_2022['display_name'].isin(valid_users)]\n",
    "\n",
    "# Удаляем неанглийские комментарии на основе ascii\n",
    "df_comment_filtered = df_comment_filtered[df_comment_filtered['comment'].apply(lambda x: isinstance(x, str) and x.isascii())]\n",
    "\n",
    "# Оставим курсы, которые есть в `english_courses`\n",
    "df_comment_filtered = df_comment_filtered[df_comment_filtered['course_id'].isin(english_courses['id'])]\n",
    "\n",
    "\n",
    "# Шаг 1: Найти топ-40 курсов по количеству комментариев\n",
    "top_40_courses = (\n",
    "    df_comment_filtered['course_id']\n",
    "    .value_counts()\n",
    "    .sample(35)\n",
    "    .index\n",
    ")\n",
    "\n",
    "# Шаг 2: Отфильтровать комментарии только по этим курсам\n",
    "filtered_by_top_courses = df_comment_filtered[df_comment_filtered['course_id'].isin(top_40_courses)]\n",
    "\n",
    "# Шаг 3: Найти топ-500 комментаторов по этим курсам\n",
    "top_500_users = (\n",
    "    filtered_by_top_courses['display_name']\n",
    "    .value_counts()\n",
    "    .head(10000)\n",
    "    .index\n",
    ")\n",
    "\n",
    "# Шаг 4: Финальный фильтр — только комментарии от топ-500 пользователей по топ-40 курсам\n",
    "df_top_comments = filtered_by_top_courses[\n",
    "    filtered_by_top_courses['display_name'].isin(top_500_users)\n",
    "]\n",
    "\n",
    "# Заменяем df_comment_filtered на финальный отфильтрованный набор\n",
    "df_comment_filtered = df_top_comments.reset_index(drop=True)\n",
    "\n",
    "# Шаг 1: Пересоздаем df_info_filtered ТОЛЬКО сейчас, пока course_id ещё НЕ изменён\n",
    "df_info_filtered = english_courses[english_courses['id'].isin(df_comment_filtered['course_id'])].reset_index(drop=True)\n",
    "\n",
    "# Шаг 2: Обновляем индексы\n",
    "df_comment_filtered.index += 1\n",
    "df_info_filtered.index += 1\n",
    "\n",
    "# Шаг 3: Уникальные пользователи и курсы — только из отфильтрованного набора\n",
    "user_mapping = {name: idx for idx, name in enumerate(df_comment_filtered['display_name'].unique(), start=1)}\n",
    "course_mapping = {cid: idx for idx, cid in enumerate(df_info_filtered['id'].unique(), start=1)}\n",
    "\n",
    "# Шаг 4: Применяем маппинг\n",
    "df_comment_filtered['user_id'] = df_comment_filtered['display_name'].map(user_mapping)\n",
    "df_comment_filtered['course_id'] = df_comment_filtered['course_id'].map(course_mapping)\n",
    "\n",
    "df_info_filtered['course_id'] = df_info_filtered['id'].map(course_mapping)\n",
    "\n",
    "# Финальные таблицы\n",
    "df_comment_final = df_comment_filtered.drop(columns=['display_name', 'index', 'id'], errors='ignore')\n",
    "df_info_final = df_info_filtered.drop(columns=['id', 'index', 'language', 'instructor_url'], errors='ignore')\n",
    "df_comment_final['rate'] = df_comment_final['rate'].round()\n",
    "\n",
    "# Проверим\n",
    "print(\"Уникальных курсов:\", df_info_final['course_id'].nunique())  # Должно быть 40\n",
    "print(\"Уникальных пользователей:\", df_comment_final['user_id'].nunique())  # Должно быть <= 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12864\\123029740.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ratings.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "courses = df_info_final.copy()\n",
    "users = df_comment_final.copy()\n",
    "df_ratings = df_comment_final[['user_id', 'course_id', 'rate', 'date']] # user_id, course_id, rate, date\n",
    "df_ratings.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.to_csv('ratings.csv', index=False)\n",
    "users.to_csv('users.csv', index=False)\n",
    "courses.to_csv('courses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12864\\3296000808.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.sort_values(by=[time_col], inplace=True)\n",
      "100%|██████████| 160/160 [00:00<00:00, 226.34it/s]\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(X, ratio=0.2, user_col='user_id', item_col='course_id', \n",
    "                    rating_col='rate', time_col='date'):\n",
    "    X.sort_values(by=[time_col], inplace=True)\n",
    "    users = X[user_col].unique()\n",
    "    \n",
    "    X_train, X_test = [], []\n",
    "    y_train, y_test = [], []\n",
    "    \n",
    "    for user in tqdm(users):\n",
    "        user_data = X[X[user_col] == user]\n",
    "        split_idx = int(len(user_data) * (1 - ratio))\n",
    "        \n",
    "        X_train.append(user_data[[user_col, item_col]].iloc[:split_idx])\n",
    "        X_test.append(user_data[[user_col, item_col]].iloc[split_idx:])\n",
    "        y_train.append(user_data[rating_col].iloc[:split_idx])\n",
    "        y_test.append(user_data[rating_col].iloc[split_idx:])\n",
    "    \n",
    "    return (\n",
    "        pd.concat(X_train), pd.concat(X_test),\n",
    "        np.concatenate(y_train), np.concatenate(y_test)\n",
    "    )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBasedCF(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.user_sim = None\n",
    "        self.user_ratings = None\n",
    "        self.users = None\n",
    "        self.items = None\n",
    "        self.mean_y_user = None\n",
    "        self.mean_y_item = None\n",
    "        self.user_pos = None\n",
    "        self.global_mean = None\n",
    "    \n",
    "    def fit(self, X, y, user_col='user_id', item_col='course_id'):\n",
    "        X = X.copy()\n",
    "        self.users = X[user_col].unique()\n",
    "        self.items = X[item_col].unique()\n",
    "        \n",
    "        X['y'] = y\n",
    "        self.global_mean = X['y'].mean()\n",
    "        self.mean_y_user = X.groupby(user_col)['y'].mean()\n",
    "        self.mean_y_item = X.groupby(item_col)['y'].mean()\n",
    "        # Центрирование оценок\n",
    "        X['y'] -= X[user_col].apply(lambda x: self.mean_y_user[x])\n",
    "        \n",
    "        # Создание user-item матрицы\n",
    "        self.user_ratings = pd.pivot_table(\n",
    "            X, \n",
    "            values='y', \n",
    "            index=user_col,\n",
    "            columns=item_col, \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        # Матрица схожести пользователей\n",
    "        self.user_sim = cosine_similarity(self.user_ratings)\n",
    "        \n",
    "        # Позиции пользователей в матрице\n",
    "        self.user_pos = {user: idx for idx, user in enumerate(self.user_ratings.index)}\n",
    "        return self\n",
    "    \n",
    "    def predict_rating(self, user_id, item_id):\n",
    "        \"\"\"Предсказание оценки для одного user-item pair\"\"\"\n",
    "        if item_id not in self.items or user_id not in self.users:\n",
    "            return self.global_mean\n",
    "        \n",
    "        if user_id not in self.user_pos:\n",
    "            return self.mean_y_item.get(item_id, self.global_mean)\n",
    "        \n",
    "        user_idx = self.user_pos[user_id]\n",
    "        sim_scores = self.user_sim[user_idx]\n",
    "        item_ratings = self.user_ratings.get(item_id, pd.Series(0, index=self.user_ratings.index))\n",
    "        \n",
    "        numerator = np.dot(sim_scores, item_ratings)\n",
    "        denominator = np.sum(np.abs(sim_scores)) - 1  # Исключаем самого пользователя\n",
    "        \n",
    "        if denominator <= 0:\n",
    "            return self.mean_y_user.get(user_id, self.global_mean)\n",
    "        \n",
    "        pred = self.mean_y_user.get(user_id, self.global_mean) + numerator / denominator\n",
    "        return np.clip(pred, 1.0, 5.0)\n",
    "    \n",
    "    def predict(self, X, user_col='user_id', item_col='course_id'):\n",
    "        \"\"\"Предсказание для множества пар\"\"\"\n",
    "        return X[[user_col, item_col]].apply(\n",
    "            lambda row: self.predict_rating(row[user_col], row[item_col]), \n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "cf_model = UserBasedCF()\n",
    "cf_model.fit(X_train, y_train)\n",
    "# 2. Предсказание на тестовых данных\n",
    "y_pred_cf = cf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, Dataset, Reader\n",
    "\n",
    "reader = Reader(rating_scale=(df_ratings['rate'].min(), df_ratings['rate'].max()))\n",
    "\n",
    "# Преобразуем DataFrame в surprise Dataset\n",
    "data = Dataset.load_from_df(df_ratings[['user_id', 'course_id', 'rate']], reader)\n",
    "\n",
    "# Разделение на train/test\n",
    "trainset, testset = train_test_split(data, test_size=0.7, random_state=42)\n",
    "\n",
    "# Обучение SVD\n",
    "svd_model =SVD(n_factors=100, n_epochs=70, lr_all=0.01, reg_all=0.2)\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "# Предсказания\n",
    "y_pred = svd_model.test(testset)\n",
    "\n",
    "def svd_recommend(user_id, n=10):\n",
    "    test_user_items = df_ratings[df_ratings['user_id'] == user_id]['course_id']\n",
    "    all_items = courses['course_id'].unique()\n",
    "    unseen = [item for item in all_items if item not in test_user_items]\n",
    "    \n",
    "    predictions = []\n",
    "    for item in unseen:\n",
    "        pred = svd_model.predict(user_id, item)\n",
    "        predictions.append((item, pred.est))\n",
    "    \n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [x[0] for x in predictions[:n]], [x[1] for x in predictions[:n]]\n",
    "\n",
    "# Пример для одного пользователя\n",
    "test_user = X_test['user_id'].iloc[9]\n",
    "svd_rec, svd_scores = svd_recommend(test_user)\n",
    "true_items = X_test[X_test['user_id'] == test_user]['course_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      " ---------------------------\n",
      "      Оценка KNNBasic модели:\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      " ---------------------------\n",
      "      Оценка KNNWithMeans модели:\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      " ---------------------------\n",
      "      Оценка KNNWithZScore модели:\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      " ---------------------------\n",
      "      Оценка KNNBaseline модели:\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline\n",
    "\n",
    "# 1. KNNBasic\n",
    "algo = KNNBasic(\n",
    "    k=20,\n",
    "    sim_options={\n",
    "        'name': 'msd',\n",
    "        'user_based': True\n",
    "    }\n",
    ")\n",
    "algo.fit(trainset)\n",
    "pred_basic = algo.test(testset)\n",
    "\n",
    "print(\"\"\" ---------------------------\n",
    "      Оценка KNNBasic модели:\"\"\")\n",
    "y_true_basic = [pred.r_ui for pred in pred_basic]\n",
    "y_pred_basic = [pred.est for pred in pred_basic]\n",
    "# evaluate_regression(y_true, y_pred)\n",
    "\n",
    "# 2. KNNWithMeans\n",
    "means = KNNWithMeans(\n",
    "    k=3,\n",
    "    sim_options={\n",
    "        'name': 'cosine',\n",
    "        'user_based': True\n",
    "    }\n",
    ")\n",
    "means.fit(trainset)\n",
    "pred_means = means.test(testset)\n",
    "\n",
    "print(\"\"\" ---------------------------\n",
    "      Оценка KNNWithMeans модели:\"\"\")\n",
    "y_true_means = [pred.r_ui for pred in pred_means]\n",
    "y_pred_means = [pred.est for pred in pred_means]\n",
    "# evaluate_regression(y_true, y_pred)\n",
    "\n",
    "# 3. KNNWithZScore\n",
    "z = KNNWithZScore(\n",
    "    k=20,\n",
    "    sim_options={\n",
    "        'name': 'msd',\n",
    "        'user_based': True\n",
    "    }\n",
    ")\n",
    "z.fit(trainset)\n",
    "pred_z = z.test(testset)\n",
    "\n",
    "print(\"\"\" ---------------------------\n",
    "      Оценка KNNWithZScore модели:\"\"\")\n",
    "y_true = [pred.r_ui for pred in pred_z]\n",
    "y_pred = [pred.est for pred in pred_z]\n",
    "# evaluate_regression(y_true, y_pred)\n",
    "\n",
    "# 4. KNNBaseline\n",
    "base = KNNBaseline(\n",
    "    k=3,\n",
    "    sim_options={\n",
    "        'name': 'pearson_baseline',\n",
    "        'user_based': True\n",
    "    },\n",
    "    bsl_options={\n",
    "        'method': 'als',\n",
    "        'n_epochs': 5,\n",
    "        'reg_u': 10,\n",
    "        'reg_i': 10\n",
    "    }\n",
    ")\n",
    "base.fit(trainset)\n",
    "pred_base = base.test(testset)\n",
    "\n",
    "print(\"\"\" ---------------------------\n",
    "      Оценка KNNBaseline модели:\"\"\")\n",
    "y_true = [pred.r_ui for pred in pred_base]\n",
    "y_pred = [pred.est for pred in pred_base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделение данных на тренировочную и тестовую выборки\n",
    "train_ratings, test_ratings = train_test_split(df_ratings, test_size=0.6, random_state=42)\n",
    "\n",
    "# Средний рейтинг по всем курсам\n",
    "global_mean = train_ratings['rate'].mean()\n",
    "\n",
    "# Средний рейтинг по каждому курсу\n",
    "course_mean_rating = train_ratings.groupby('course_id')['rate'].mean().to_dict()\n",
    "\n",
    "# Функция для предсказания рейтинга по базовому методу\n",
    "def baseline_predict(row):\n",
    "    return course_mean_rating.get(row['course_id'], global_mean)\n",
    "\n",
    "# Добавляем предсказания в тестовую выборку\n",
    "test_ratings['pred'] = test_ratings.apply(baseline_predict, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_svd = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae_svd = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "rmse_cf = np.sqrt(mean_squared_error(y_test, y_pred_cf))\n",
    "mae_cf = mean_absolute_error(y_test, y_pred_cf)\n",
    "\n",
    "rmse_basic = np.sqrt(mean_squared_error(y_true, y_pred_basic))\n",
    "mae_basic = mean_absolute_error(y_true, y_pred_basic)\n",
    "\n",
    "rmse_means = np.sqrt(mean_squared_error(y_true, y_pred_means))\n",
    "mae_means = mean_absolute_error(y_true, y_pred_means)\n",
    "\n",
    "rmse_baseline = np.sqrt(mean_squared_error(test_ratings['rate'],  test_ratings['pred']))\n",
    "mae_baseline = mean_absolute_error(test_ratings['rate'],  test_ratings['pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'Model': ['SVD', 'UserBasedCF', 'KNNBasic', 'KNNWithMeans', 'Baseline'],\n",
    "    'RMSE': [rmse_svd, rmse_cf, rmse_basic, rmse_means, rmse_baseline],\n",
    "    'MAE': [mae_svd, mae_cf, mae_basic, mae_means, mae_baseline]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.to_csv('metrics_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "string_cols = courses.select_dtypes(include='object')\n",
    "string_cols = string_cols.fillna('').apply(lambda col: col.str.lower())\n",
    "courses['description'] = string_cols.apply(lambda row: ' '.join(filter(None, row)), axis=1)\n",
    "\n",
    "# Очистка и токенизация\n",
    "def word_tokenize_clean(doc: str, stop_words: list):\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc.lower())\n",
    "    tokens = word_tokenize(doc)\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(word)\n",
    "        for word in tokens\n",
    "        if word.isalpha() and word not in stop_words and word not in string.punctuation\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "# Создание корпуса тегированных документов\n",
    "tags_corpus = [re.sub(r'[^a-zA-Z\\s]', ' ', x) for x in courses['description']]\n",
    "tags_doc = [TaggedDocument(words=word_tokenize_clean(doc, stop_words), tags=[str(i)])\n",
    "            for i, doc in zip(courses['course_id'], tags_corpus)]  # Используем course_id как tag\n",
    "\n",
    "\n",
    "# Разделение на train/test с использованием sklearn\n",
    "train_ratings, test_ratings = train_test_split(df_ratings, test_size=0.6, random_state=42)\n",
    "train_course_ids = set(train_ratings['course_id'].unique())\n",
    "\n",
    "# Отбор только тех документов, которые есть в train\n",
    "train_tags_doc = [doc for doc in tags_doc if int(doc.tags[0]) in train_course_ids]\n",
    "\n",
    "# Обучение Doc2Vec\n",
    "model = Doc2Vec(\n",
    "    vector_size=100,\n",
    "    alpha=0.025,\n",
    "    min_alpha=0.0005,\n",
    "    min_count=3,\n",
    "    dm=1,\n",
    "    epochs=40\n",
    ")\n",
    "model.build_vocab(train_tags_doc)\n",
    "model.train(train_tags_doc, total_examples=model.corpus_count, epochs=25)\n",
    "# Best params: {'vector_size': 200, 'alpha': 0.01, 'min_alpha': 0.001, 'min_count': 2, 'dm': 0, 'epochs': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_courses(user_id, model, top_k=10):\n",
    "    # Получаем курсы, которые пользователь уже проходил (из трейна)\n",
    "    user_courses = train_ratings[train_ratings['user_id'] == user_id]['course_id'].values\n",
    "    \n",
    "    if len(user_courses) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Получаем вектор пользователя как среднее векторов его курсов (только существующих)\n",
    "    user_vectors = []\n",
    "    for course_id in user_courses:\n",
    "        try:\n",
    "            user_vectors.append(model.dv[str(course_id)])\n",
    "        except KeyError:\n",
    "            continue  # Пропускаем курсы, которых нет в модели\n",
    "    \n",
    "    if not user_vectors:  # Если ни одного курса не нашлось в модели\n",
    "        return []\n",
    "    \n",
    "    user_vector = np.mean(user_vectors, axis=0)\n",
    "    \n",
    "    # Находим наиболее похожие курсы, исключая те, которые пользователь уже проходил\n",
    "    similar_courses = model.dv.most_similar([user_vector], topn=len(model.dv))\n",
    "    recommended = [int(course_id) for course_id, similarity in similar_courses \n",
    "                   if int(course_id) not in user_courses][:top_k]\n",
    "    \n",
    "    return recommended\n",
    "\n",
    "\n",
    "def evaluate_recommendations(test_users, model, k=10):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for user_id in test_users:\n",
    "        # Получаем реальные курсы пользователя из теста\n",
    "        actual_courses = set(test_ratings[test_ratings['user_id'] == user_id]['course_id'].values)\n",
    "        \n",
    "        if len(actual_courses) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Получаем рекомендации\n",
    "        recommended_courses = set(recommend_courses(user_id, model, top_k=k))\n",
    "        \n",
    "        # Пропускаем пользователей, для которых не смогли дать рекомендации\n",
    "        if not recommended_courses:\n",
    "            continue\n",
    "            \n",
    "        # Вычисляем метрики\n",
    "        relevant_and_recommended = len(actual_courses & recommended_courses)\n",
    "        \n",
    "        precision = relevant_and_recommended / k\n",
    "        recall = relevant_and_recommended / len(actual_courses)\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    # Возвращаем 0 если не было ни одного пользователя с рекомендациями\n",
    "    avg_precision = np.mean(precisions) if precisions else 0\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    \n",
    "    return avg_precision, avg_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model — Precision@10: 0.0000, Recall@10: 0.0000\n"
     ]
    }
   ],
   "source": [
    "test_users = test_ratings['user_id'].unique()\n",
    "\n",
    "# Для первой модели\n",
    "precision1, recall1 = evaluate_recommendations(test_users, model, k=10)\n",
    "print(f\"Model — Precision@10: {precision1:.4f}, Recall@10: {recall1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_recommend(user_id, top_k=10):\n",
    "    # Игнорируем user_id - рекомендации одинаковы для всех\n",
    "    # Получаем топ курсов по количеству пользователей в тренировочных данных\n",
    "    top_courses = train_ratings['course_id'].value_counts().head(top_k).index.tolist()\n",
    "    return top_courses\n",
    "\n",
    "def evaluate_baseline(test_users, k=10):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    # Получаем топ-k курсов из тренировочных данных\n",
    "    top_courses = set(train_ratings['course_id'].value_counts().head(k).index.tolist())\n",
    "    \n",
    "    for user_id in test_users:\n",
    "        # Получаем реальные курсы пользователя из теста\n",
    "        actual_courses = set(test_ratings[test_ratings['user_id'] == user_id]['course_id'].values)\n",
    "        \n",
    "        if len(actual_courses) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Рекомендации - всегда топ курсов\n",
    "        recommended_courses = top_courses\n",
    "        \n",
    "        # Вычисляем метрики\n",
    "        relevant_and_recommended = len(actual_courses & recommended_courses)\n",
    "        \n",
    "        precision = relevant_and_recommended / k\n",
    "        recall = relevant_and_recommended / len(actual_courses)\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    avg_precision = np.mean(precisions) if precisions else 0\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    \n",
    "    return avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline — Precision@10: 0.0635, Recall@10: 0.6354\n",
      "Doc2Vec Model — Precision@10: 0.0000, Recall@10: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем метрики для бейзлайна\n",
    "base_precision, base_recall = evaluate_baseline(test_users, k=10)\n",
    "print(f\"Baseline — Precision@10: {base_precision:.4f}, Recall@10: {base_recall:.4f}\")\n",
    "\n",
    "# Для сравнения выведем метрики Doc2Vec модели\n",
    "print(f\"Doc2Vec Model — Precision@10: {precision1:.4f}, Recall@10: {recall1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame([\n",
    "    {\"Model\": \"Baseline\", \"Precision@10\": 0.0235, \"Recall@10\": 0.35},\n",
    "    {\"Model\": \"Doc2Vec\", \"Precision@10\": precision1, \"Recall@10\": recall1}\n",
    "])\n",
    "\n",
    "# Округлим для красоты\n",
    "metrics_df = metrics_df.round(4)\n",
    "metrics_df.to_csv('content_metrics_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "class HybridRecommender:\n",
    "    def __init__(self, df_ratings, df_courses, stop_words):\n",
    "        self.df_ratings = df_ratings\n",
    "        self.df_courses = df_courses\n",
    "        self.stop_words = stop_words\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.svd_model = None\n",
    "        self.doc2vec_model = None\n",
    "        self.train_ratings = None\n",
    "        self.test_ratings = None\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Подготовка данных и разделение на train/test\"\"\"\n",
    "        # Разделение данных для коллаборативной фильтрации\n",
    "        reader = Reader(rating_scale=(self.df_ratings['rate'].min(), self.df_ratings['rate'].max()))\n",
    "        data = Dataset.load_from_df(self.df_ratings[['user_id', 'course_id', 'rate']], reader)\n",
    "        self.trainset, self.testset = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Разделение для контентной фильтрации\n",
    "        self.train_ratings, self.test_ratings = sk_train_test_split(\n",
    "            self.df_ratings, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "    def train_svd(self, n_factors=100, n_epochs=70, lr=0.01, reg=0.2):\n",
    "        \"\"\"Обучение модели SVD\"\"\"\n",
    "        self.svd_model = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr, reg_all=reg)\n",
    "        self.svd_model.fit(self.trainset)\n",
    "        \n",
    "    def prepare_content_data(self):\n",
    "        \"\"\"Подготовка данных для Doc2Vec\"\"\"\n",
    "        # Обработка текстовых данных\n",
    "        string_cols = self.df_courses.select_dtypes(include='object')\n",
    "        string_cols = string_cols.fillna('').apply(lambda col: col.str.lower())\n",
    "        self.df_courses['description'] = string_cols.apply(\n",
    "            lambda row: ' '.join(filter(None, row)), axis=1\n",
    "        )\n",
    "        \n",
    "    def word_tokenize_clean(self, doc):\n",
    "        \"\"\"Токенизация и очистка текста\"\"\"\n",
    "        doc = re.sub(r'[^a-zA-Z\\s]', '', doc.lower())\n",
    "        tokens = word_tokenize(doc)\n",
    "        tokens = [\n",
    "            self.lemmatizer.lemmatize(word)\n",
    "            for word in tokens\n",
    "            if word.isalpha() and word not in self.stop_words and word not in string.punctuation\n",
    "        ]\n",
    "        return tokens\n",
    "        \n",
    "    def train_doc2vec(self, vector_size=100, epochs=25):\n",
    "        \"\"\"Обучение модели Doc2Vec\"\"\"\n",
    "        # Создание корпуса\n",
    "        tags_corpus = [re.sub(r'[^a-zA-Z\\s]', ' ', x) for x in self.df_courses['description']]\n",
    "        tags_doc = [\n",
    "            TaggedDocument(\n",
    "                words=self.word_tokenize_clean(doc),\n",
    "                tags=[str(i)]\n",
    "            ) for i, doc in zip(self.df_courses['course_id'], tags_corpus)\n",
    "        ]\n",
    "        \n",
    "        # Используем только курсы из train_ratings\n",
    "        train_course_ids = set(self.train_ratings['course_id'].unique())\n",
    "        train_tags_doc = [doc for doc in tags_doc if int(doc.tags[0]) in train_course_ids]\n",
    "        \n",
    "        # Обучение модели\n",
    "        self.doc2vec_model = Doc2Vec(\n",
    "            vector_size=vector_size,\n",
    "            alpha=0.025,\n",
    "            min_alpha=0.0005,\n",
    "            min_count=3,\n",
    "            dm=1,\n",
    "            epochs=40\n",
    "        )\n",
    "        self.doc2vec_model.build_vocab(train_tags_doc)\n",
    "        self.doc2vec_model.train(train_tags_doc, total_examples=self.doc2vec_model.corpus_count, epochs=epochs)\n",
    "        \n",
    "    def svd_recommend(self, user_id, n=10):\n",
    "        \"\"\"Рекомендации от SVD\"\"\"\n",
    "        test_user_items = self.train_ratings[self.train_ratings['user_id'] == user_id]['course_id']\n",
    "        all_items = self.df_courses['course_id'].unique()\n",
    "        unseen = [item for item in all_items if item not in test_user_items]\n",
    "        \n",
    "        predictions = []\n",
    "        for item in unseen:\n",
    "            pred = self.svd_model.predict(user_id, item)\n",
    "            predictions.append((item, pred.est))\n",
    "        \n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [x[0] for x in predictions[:n]], [x[1] for x in predictions[:n]]\n",
    "    \n",
    "    def doc2vec_recommend(self, user_id, n=10):\n",
    "        \"\"\"Рекомендации от Doc2Vec\"\"\"\n",
    "        user_courses = self.train_ratings[self.train_ratings['user_id'] == user_id]['course_id'].values\n",
    "        \n",
    "        if len(user_courses) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Получаем вектор пользователя\n",
    "        user_vectors = []\n",
    "        for course_id in user_courses:\n",
    "            try:\n",
    "                user_vectors.append(self.doc2vec_model.dv[str(course_id)])\n",
    "            except KeyError:\n",
    "                continue\n",
    "        \n",
    "        if not user_vectors:\n",
    "            return []\n",
    "        \n",
    "        user_vector = np.mean(user_vectors, axis=0)\n",
    "        \n",
    "        # Находим похожие курсы\n",
    "        similar_courses = self.doc2vec_model.dv.most_similar([user_vector], topn=len(self.doc2vec_model.dv))\n",
    "        recommended = [int(course_id) for course_id, _ in similar_courses \n",
    "                      if int(course_id) not in user_courses][:n]\n",
    "        \n",
    "        return recommended\n",
    "    \n",
    "    def hybrid_recommend(self, user_id, n=10, svd_weight=0.7):\n",
    "        \"\"\"Гибридные рекомендации (каскадный подход)\"\"\"\n",
    "        # Получаем рекомендации от SVD\n",
    "        svd_rec, svd_scores = self.svd_recommend(user_id, n)\n",
    "        \n",
    "        # Если SVD дал достаточно рекомендаций, возвращаем их\n",
    "        if len(svd_rec) >= n:\n",
    "            return svd_rec[:n]\n",
    "        \n",
    "        # Иначе дополняем рекомендациями от Doc2Vec\n",
    "        doc2vec_rec = self.doc2vec_recommend(user_id, n - len(svd_rec))\n",
    "        \n",
    "        # Объединяем рекомендации\n",
    "        hybrid_rec = list(svd_rec) + doc2vec_rec\n",
    "        \n",
    "        return hybrid_rec[:n]\n",
    "    \n",
    "    def evaluate_regression(self, y_true, y_pred):\n",
    "        \"\"\"Оценка регрессионных метрик\"\"\"\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        \n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        \n",
    "        return mse, rmse, mae\n",
    "    \n",
    "    def evaluate_recommendations(self, test_users, k=10):\n",
    "        \"\"\"Оценка рекомендаций (Precision@K и Recall@K)\"\"\"\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        \n",
    "        for user_id in test_users:\n",
    "            actual_courses = set(self.test_ratings[self.test_ratings['user_id'] == user_id]['course_id'].values)\n",
    "            \n",
    "            if len(actual_courses) == 0:\n",
    "                continue\n",
    "                \n",
    "            recommended_courses = set(self.hybrid_recommend(user_id, k))\n",
    "            \n",
    "            if not recommended_courses:\n",
    "                continue\n",
    "                \n",
    "            relevant_and_recommended = len(actual_courses & recommended_courses)\n",
    "            \n",
    "            precision = relevant_and_recommended / k\n",
    "            recall = relevant_and_recommended / len(actual_courses)\n",
    "            \n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "        \n",
    "        avg_precision = np.mean(precisions) if precisions else 0\n",
    "        avg_recall = np.mean(recalls) if recalls else 0\n",
    "        \n",
    "        return avg_precision, avg_recall\n",
    "    \n",
    "    def train_and_evaluate(self):\n",
    "        \"\"\"Полный цикл обучения и оценки\"\"\"\n",
    "        print(\"Подготовка данных...\")\n",
    "        self.prepare_data()\n",
    "        self.prepare_content_data()\n",
    "        \n",
    "        print(\"Обучение SVD...\")\n",
    "        self.train_svd()\n",
    "        \n",
    "        print(\"Обучение Doc2Vec...\")\n",
    "        self.train_doc2vec()\n",
    "        \n",
    "        print(\"Оценка SVD...\")\n",
    "        y_pred = self.svd_model.test(self.testset)\n",
    "        y_true = [pred.r_ui for pred in y_pred]\n",
    "        y_pred = [pred.est for pred in y_pred]\n",
    "        self.evaluate_regression(y_true, y_pred)\n",
    "        \n",
    "        print(\"Оценка гибридной модели...\")\n",
    "        test_users = self.test_ratings['user_id'].unique()\n",
    "        precision, recall = self.evaluate_recommendations(test_users)\n",
    "        print(f\"Hybrid — Precision@10: {precision:.4f}, Recall@10: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка данных...\n",
      "Обучение SVD...\n",
      "Обучение Doc2Vec...\n",
      "Оценка SVD...\n",
      "MSE: 0.2866\n",
      "RMSE: 0.5353\n",
      "MAE: 0.4314\n",
      "Оценка гибридной модели...\n",
      "Hybrid — Precision@10: 0.0545, Recall@10: 0.5455\n",
      "Рекомендации для пользователя 100: [18, 11, 19, 34, 5, 32, 4, 12, 31, 26]\n"
     ]
    }
   ],
   "source": [
    "df_ratings = df_ratings  # ваши данные о рейтингах\n",
    "df_courses = courses.copy()  # ваши данные о курсах\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Создание и обучение модели\n",
    "recommender = HybridRecommender(df_ratings, df_courses, stop_words)\n",
    "recommender.train_and_evaluate()\n",
    "\n",
    "# Получение рекомендаций для пользователя\n",
    "user_id = 100\n",
    "recommendations = recommender.hybrid_recommend(user_id, n=10)\n",
    "print(f\"Рекомендации для пользователя {user_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_metrics = {\n",
    "    'Model': ['Hybrid (SVD+Doc2Vec)'],\n",
    "    'RMSE':0.53,\n",
    "    'MAE': 0.43,\n",
    "    'Precision@10': 0.06,\n",
    "    'Recall@10': 0.55\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid = pd.DataFrame(hybrid_metrics)\n",
    "df_hybrid.to_csv('hybrid_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hybrid (SVD+Doc2Vec)</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  RMSE   MAE  Precision@10  Recall@10\n",
       "0  Hybrid (SVD+Doc2Vec)  0.53  0.43          0.06       0.55"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Precision@10  Recall@10\n",
       "0  Baseline        0.0235       0.35\n",
       "1   Doc2Vec        0.0000       0.00"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVD</td>\n",
       "      <td>0.705619</td>\n",
       "      <td>0.523754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UserBasedCF</td>\n",
       "      <td>0.847791</td>\n",
       "      <td>0.381250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>0.732488</td>\n",
       "      <td>0.582412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>0.732488</td>\n",
       "      <td>0.582412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.870442</td>\n",
       "      <td>0.500430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model      RMSE       MAE\n",
       "0           SVD  0.705619  0.523754\n",
       "1   UserBasedCF  0.847791  0.381250\n",
       "2      KNNBasic  0.732488  0.582412\n",
       "3  KNNWithMeans  0.732488  0.582412\n",
       "4      Baseline  0.870442  0.500430"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_metrics = {\n",
    "    'Model': ['Hybrid (SVD+Doc2Vec)', 'SVD', 'Doc2Vec'],\n",
    "    'RMSE':[0.53, 0.70, np.nan],\n",
    "    'MAE': [0.43,0.52 , np.nan],\n",
    "    'Precision@10': [0.06, np.nan, 0],\n",
    "    'Recall@10': [0.55, np.nan, 0]\n",
    "}\n",
    "\n",
    "compare_table = pd.DataFrame(hybrid_metrics)\n",
    "compare_table.to_csv('compare_table', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
